{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2A Updated.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"EdOb05CI0Px4","colab_type":"code","outputId":"7e07348b-1bf1-4306-9ac0-e52140540f08","executionInfo":{"status":"ok","timestamp":1548794367218,"user_tz":480,"elapsed":1474,"user":{"displayName":"Rohit Bansal","photoUrl":"https://lh5.googleusercontent.com/-qk5Oe2_Dv1E/AAAAAAAAAAI/AAAAAAAAFZY/Cn38EV-FgtM/s64/photo.jpg","userId":"14532860681730767885"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"cell_type":"code","source":["import os,urllib.request\n","datapath = '../Data/MNISTData/'\n","if not os.path.exists(datapath):\n","    os.makedirs(datapath)\n","\n","urls = ['http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n","       'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n","       'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n","       'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz']\n","\n","for url in urls:\n","    filename = url.split('/')[-1]\n","    if os.path.exists(datapath+filename):\n","        print(filename, ' already exists')\n","    else:\n","        print('Downloading ',filename)\n","        urllib.request.urlretrieve (url, datapath+filename)\n","     \n","print('All files are downloaded for MNIST dataset')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading  train-images-idx3-ubyte.gz\n","Downloading  train-labels-idx1-ubyte.gz\n","Downloading  t10k-images-idx3-ubyte.gz\n","Downloading  t10k-labels-idx1-ubyte.gz\n","All files are downloaded for MNIST dataset\n"],"name":"stdout"}]},{"metadata":{"id":"9Q8DT9vP0X7o","colab_type":"code","outputId":"b0db5c45-8111-4ced-91c1-c949ef738a57","executionInfo":{"status":"ok","timestamp":1548794371761,"user_tz":480,"elapsed":778,"user":{"displayName":"Rohit Bansal","photoUrl":"https://lh5.googleusercontent.com/-qk5Oe2_Dv1E/AAAAAAAAAAI/AAAAAAAAFZY/Cn38EV-FgtM/s64/photo.jpg","userId":"14532860681730767885"}},"colab":{"base_uri":"https://localhost:8080/","height":192}},"cell_type":"code","source":["import os,gzip,shutil\n","\n","datapath = '../Data/MNISTData/'  \n","files = os.listdir(datapath)\n","for file in files:\n","    if file.endswith('gz'):\n","        print('Extracting ',file)\n","        with gzip.open(datapath+file, 'rb') as f_in:\n","            with open(datapath+file.split('.')[0], 'wb') as f_out:\n","                shutil.copyfileobj(f_in, f_out)\n","print('Extraction Complete')\n","\n","for file in files:\n","    print('Removing ',file)\n","    os.remove(datapath+file)\n","print ('All archives removed')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Extracting  train-images-idx3-ubyte.gz\n","Extracting  t10k-labels-idx1-ubyte.gz\n","Extracting  train-labels-idx1-ubyte.gz\n","Extracting  t10k-images-idx3-ubyte.gz\n","Extraction Complete\n","Removing  train-images-idx3-ubyte.gz\n","Removing  t10k-labels-idx1-ubyte.gz\n","Removing  train-labels-idx1-ubyte.gz\n","Removing  t10k-images-idx3-ubyte.gz\n","All archives removed\n"],"name":"stdout"}]},{"metadata":{"id":"l6VpVL1Z0ZAx","colab_type":"code","outputId":"3b9627fa-5d48-4f36-b11c-dc02b7eb1034","executionInfo":{"status":"ok","timestamp":1548794379763,"user_tz":480,"elapsed":574,"user":{"displayName":"Rohit Bansal","photoUrl":"https://lh5.googleusercontent.com/-qk5Oe2_Dv1E/AAAAAAAAAAI/AAAAAAAAFZY/Cn38EV-FgtM/s64/photo.jpg","userId":"14532860681730767885"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"cell_type":"code","source":["import os,codecs\n","import numpy as np\n","\n","datapath = '../Data/MNISTData/'\n","files = os.listdir(datapath)\n","\n","def get_int(b):\n","  return int(codecs.encode(b, 'hex'), 16)\n","\n","data_dict = {}\n","for file in files:\n","    if file.endswith('ubyte'):\n","        print('Reading ',file)\n","        with open (datapath+file,'rb') as f:\n","            data = f.read()\n","            type = get_int(data[:4])\n","            length = get_int(data[4:8])\n","            if (type == 2051):\n","                category = 'images'\n","                num_rows = get_int(data[8:12])\n","                num_cols = get_int(data[12:16])\n","                parsed = np.frombuffer(data,dtype = np.uint8, offset = 16)\n","                parsed = parsed.reshape(length,num_rows*num_cols)\n","            elif(type == 2049):\n","                category = 'labels'\n","                parsed = np.frombuffer(data, dtype=np.uint8, offset=8)\n","                parsed = parsed.reshape(length)\n","            if (length==10000):\n","                set = 'test'\n","            elif (length==60000):\n","                set = 'train'\n","            data_dict[set+'_'+category] = parsed\n","\n","print(data_dict.keys())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Reading  t10k-labels-idx1-ubyte\n","Reading  train-labels-idx1-ubyte\n","Reading  t10k-images-idx3-ubyte\n","Reading  train-images-idx3-ubyte\n","dict_keys(['test_labels', 'train_labels', 'test_images', 'train_images'])\n"],"name":"stdout"}]},{"metadata":{"id":"2iJjfHTW0lzx","colab_type":"code","outputId":"2d5cfffa-dfd5-495a-f844-e65b927f1d61","executionInfo":{"status":"ok","timestamp":1548796610404,"user_tz":480,"elapsed":370051,"user":{"displayName":"Rohit Bansal","photoUrl":"https://lh5.googleusercontent.com/-qk5Oe2_Dv1E/AAAAAAAAAAI/AAAAAAAAFZY/Cn38EV-FgtM/s64/photo.jpg","userId":"14532860681730767885"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"cell_type":"code","source":["from PIL import Image, ImageDraw\n","import matplotlib.pyplot as plt\n","import cv2\n","\n","train_images = data_dict['train_images']\n","train_labels = data_dict['train_labels']\n","\n","train0 = train_images[np.where(train_labels[:] == 0)]\n","train1 = train_images[np.where(train_labels[:] == 1)]\n","train2 = train_images[np.where(train_labels[:] == 2)]\n","train3 = train_images[np.where(train_labels[:] == 3)]\n","train4 = train_images[np.where(train_labels[:] == 4)]\n","train5 = train_images[np.where(train_labels[:] == 5)]\n","train6 = train_images[np.where(train_labels[:] == 6)]\n","train7 = train_images[np.where(train_labels[:] == 7)]\n","train8 = train_images[np.where(train_labels[:] == 8)]\n","train9 = train_images[np.where(train_labels[:] == 9)]\n","\n","l = train_images.shape[0]\n","\n","STRETCHED_TRAIN_IMAGES = train_images.reshape(l, 28, 28)\n","\n","for i in range (l):\n","  \n","  min_j, min_k, max_j, max_k = 255,255,0,0;\n","  y=[]\n","\n","  for j in range (28):\n","    for k in range (28):\n","      if(STRETCHED_TRAIN_IMAGES[i][j][k] > 0):\n","        if(j < min_j):\n","          min_j = j\n","        if(j > max_j):\n","           max_j = j\n","        if(k < min_k):\n","          min_k = k\n","        if(k > max_k):\n","          max_k = k\n","  \n","  for j in range (min_j, max_j+1):\n","    x=[]\n","    for k in range (min_k, max_k+1):\n","       x.append(STRETCHED_TRAIN_IMAGES[i][j][k])\n","    y.append(x)\n","  \n","  arr = np.array(y)\n","  resized = cv2.resize(arr, (20,20), interpolation = cv2.INTER_NEAREST)\n","\n","  #img = Image.fromarray(resized)\n","  #THIS FUNCTION NOT WORKING\n","  #img.resize((20,20))\n","  #a = np.asarray(img)\n","  #print(np.size(a))\n","  #plt.imshow(img)\n","  \n","  if i == 0:\n","    each_image = resized.flatten().reshape(1,400)\n","  else:\n","    each_image = np.append(each_image, resized.flatten().reshape(1,400), axis = 0)\n","  \n","train0_stretched = each_image[np.where(train_labels[:] == 0)]\n","train1_stretched = each_image[np.where(train_labels[:] == 1)]\n","train2_stretched = each_image[np.where(train_labels[:] == 2)]\n","train3_stretched = each_image[np.where(train_labels[:] == 3)]\n","train4_stretched = each_image[np.where(train_labels[:] == 4)]\n","train5_stretched = each_image[np.where(train_labels[:] == 5)]\n","train6_stretched = each_image[np.where(train_labels[:] == 6)]\n","train7_stretched = each_image[np.where(train_labels[:] == 7)]\n","train8_stretched = each_image[np.where(train_labels[:] == 8)]\n","train9_stretched = each_image[np.where(train_labels[:] == 9)]\n","    \n","    \n","print('Untouched and stretched images generated successfully !')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[ 0  0  0 ...  0  0  0]\n"," [ 0  0  0 ...  0  0  0]\n"," [ 0  0  0 ...  0  0  0]\n"," [ 0  0  0 ...  0  0  0]\n"," [ 0  0  0 ... 42  0  0]]\n","Untouched and stretched images generated successfully !\n"],"name":"stdout"}]},{"metadata":{"id":"npE3JNvQ0z1E","colab_type":"code","colab":{}},"cell_type":"code","source":["tim = data_dict['test_images']\n","trl = data_dict['test_labels']\n","\n","l = tim.shape[0]\n","\n","STRETCHED_TEST_IMAGES = tim.reshape(l, 28, 28)\n","\n","for i in range (l):\n","  \n","  min_j, min_k, max_j, max_k = 255,255,0,0;\n","  y=[]\n","\n","  for j in range (28):\n","    for k in range (28):\n","      if(STRETCHED_TEST_IMAGES[i][j][k] > 0):\n","        if(j < min_j):\n","          min_j = j\n","        if(j > max_j):\n","           max_j = j\n","        if(k < min_k):\n","          min_k = k\n","        if(k > max_k):\n","          max_k = k\n","  for j in range (min_j, max_j+1):\n","    x=[]\n","    for k in range (min_k, max_k+1):\n","       x.append(STRETCHED_TEST_IMAGES[i][j][k])\n","    y.append(x)\n","  \n","  #print(y)\n","  #print(np.size(np.asarray(y)))\n","  \n","  img = Image.fromarray(np.asarray(y))\n","  #THIS FUNCTION NOT WORKING\n","  img.resize((20,20))\n","  #a = np.asarray(img)\n","  #print(np.size(a))\n","  plt.imshow(img)\n","  \n","  if i == 0:\n","    test_stretched = np.asarray(img).flatten().reshape(400,1)\n","  else:\n","    np.append(test_stretched, np.asarray(img).flatten().reshape(400,1), axis = 0)\n","  \n","  #if np.size(np.asarray(y)) <400:\n","    #break\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"r06rx8qq0mtP","colab_type":"code","colab":{}},"cell_type":"code","source":["no_of_samples = train_images.shape[0]\n","image_size = np.size(train0[0])\n","\n","P_0 = np.log((np.size(train0)/image_size)/no_of_samples)\n","P_1 = np.log((np.size(train1)/image_size)/no_of_samples)\n","P_2 = np.log((np.size(train2)/image_size)/no_of_samples)\n","P_3 = np.log((np.size(train3)/image_size)/no_of_samples)\n","P_4 = np.log((np.size(train4)/image_size)/no_of_samples)\n","P_5 = np.log((np.size(train5)/image_size)/no_of_samples)\n","P_6 = np.log((np.size(train6)/image_size)/no_of_samples)\n","P_7 = np.log((np.size(train7)/image_size)/no_of_samples)\n","P_8 = np.log((np.size(train8)/image_size)/no_of_samples)\n","P_9 = np.log((np.size(train9)/image_size)/no_of_samples)\n","\n","\n","print('Successfully generated probabilities !')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wyLu4mxXl_tc","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","def generateMeanVar(train0, train1, train2, train3, train4, train5, train6, train7, train8, train9): \n","  mean_0 = (np.mean(train0, axis =0))\n","  mean_1 = (np.mean(train1, axis =0))\n","  mean_2 = (np.mean(train2, axis =0))\n","  mean_3 = (np.mean(train3, axis =0))\n","  mean_4 = (np.mean(train4, axis =0))\n","  mean_5 = (np.mean(train5, axis =0))\n","  mean_6 = (np.mean(train6, axis =0))\n","  mean_7 = (np.mean(train7, axis =0))\n","  mean_8 = (np.mean(train8, axis =0))\n","  mean_9 = (np.mean(train9, axis =0))\n","  var_0 = (np.std(train0, axis =0))\n","  var_1 = (np.std(train1, axis =0))\n","  var_2 = (np.std(train2, axis =0))\n","  var_3 = (np.std(train3, axis =0))\n","  var_4 = (np.std(train4, axis =0))\n","  var_5 = (np.std(train5, axis =0))\n","  var_6 = (np.std(train6, axis =0))\n","  var_7 = (np.std(train7, axis =0))\n","  var_8 = (np.std(train8, axis =0))\n","  var_9 = (np.std(train9, axis =0))\n","\n","  nonzerovarrow0 = np.where(var_0[:]!=0) \n","  nonzerovarrow1 = np.where(var_1[:]!=0) \n","  nonzerovarrow2 = np.where(var_2[:]!=0) \n","  nonzerovarrow3 = np.where(var_3[:]!=0) \n","  nonzerovarrow4 = np.where(var_4[:]!=0) \n","  nonzerovarrow5 = np.where(var_5[:]!=0) \n","  nonzerovarrow6 = np.where(var_6[:]!=0) \n","  nonzerovarrow7 = np.where(var_7[:]!=0) \n","  nonzerovarrow8 = np.where(var_8[:]!=0)\n","  nonzerovarrow9 = np.where(var_9[:]!=0) \n","  \n","  print('Mean and Variance generated successfully !')\n","  \n","  return (mean_0, mean_1, mean_2, mean_3, mean_4, mean_5, mean_6, mean_7, mean_8, mean_9, \n","          var_0, var_1, var_2, var_3, var_4, var_5, var_6, var_7, var_8, var_9,\n","         [nonzerovarrow0,nonzerovarrow1,nonzerovarrow2,nonzerovarrow3,nonzerovarrow4,\n","          nonzerovarrow5,nonzerovarrow6,nonzerovarrow7,nonzerovarrow8,nonzerovarrow9])\n","\n","\n","    \n","  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"zueUcHzemKb3","colab_type":"code","colab":{}},"cell_type":"code","source":["from scipy.stats import norm\n","\n","test_images = data_dict['test_images']\n","test_labels = data_dict['test_labels']\n","no_of_tests = test_images.shape[0]\n","\n","\n","def getHighestProbability(probs):\n","  max = probs[0]\n","  res = 0\n","  for i in range(1,10):\n","    if probs[i] > max:\n","      max = probs[i]\n","      res = i\n","  return res\n","\n","def getAccuracy(TEST_IMAGES, test_labels, distribution, mean_0, mean_1, mean_2, mean_3, mean_4, mean_5, mean_6, mean_7, mean_8, mean_9, \n","                var_0, var_1, var_2, var_3, var_4, var_5, var_6, var_7, var_8, var_9, P,nonzerovarrow):\n","  accuracy = 0\n","  for i in range(0,no_of_tests):\n","    x = TEST_IMAGES[i,:]\n","    \n","    if(distribution == 'normal'):\n","      prob0 =P[0]+sum(norm.logpdf(x[nonzerovarrow[0]], mean_0[nonzerovarrow[0]], var_0[nonzerovarrow[0]]))\n","      prob1 =P[1]+sum(norm.logpdf(x[nonzerovarrow[1]], mean_1[nonzerovarrow[1]], var_1[nonzerovarrow[1]]))\n","      prob2 =P[2]+sum(norm.logpdf(x[nonzerovarrow[2]], mean_2[nonzerovarrow[2]], var_2[nonzerovarrow[2]]))\n","      prob3 =P[3]+sum(norm.logpdf(x[nonzerovarrow[3]], mean_3[nonzerovarrow[3]], var_3[nonzerovarrow[3]]))\n","      prob4 =P[4]+sum(norm.logpdf(x[nonzerovarrow[4]], mean_4[nonzerovarrow[4]], var_4[nonzerovarrow[4]]))\n","      prob5 =P[5]+sum(norm.logpdf(x[nonzerovarrow[5]], mean_5[nonzerovarrow[5]], var_5[nonzerovarrow[5]]))\n","      prob6 =P[6]+sum(norm.logpdf(x[nonzerovarrow[6]], mean_6[nonzerovarrow[6]], var_6[nonzerovarrow[6]]))\n","      prob7 =P[7]+sum(norm.logpdf(x[nonzerovarrow[7]], mean_7[nonzerovarrow[7]], var_7[nonzerovarrow[7]]))\n","      prob8 =P[8]+sum(norm.logpdf(x[nonzerovarrow[8]], mean_8[nonzerovarrow[8]], var_8[nonzerovarrow[8]]))\n","      prob9 =P[9]+sum(norm.logpdf(x[nonzerovarrow[9]], mean_9[nonzerovarrow[9]], var_9[nonzerovarrow[9]])) \n","\n","    res = getHighestProbability([prob0, prob1, prob2, prob3, prob4, prob5, prob6, prob7, prob8, prob9])\n","\n","    if(res == test_labels[i]):\n","      accuracy += 1\n","      \n","    if i%1000 == 0:\n","      print(i)\n","      \n","  return accuracy/no_of_tests\n","\n","(mean_0, mean_1, mean_2, mean_3, mean_4, mean_5, mean_6, mean_7, mean_8, mean_9, var_0, var_1, var_2, var_3, var_4, var_5, var_6, var_7, var_8, var_9, nonzerovarrow) = generateMeanVar(train0, train1, train2, train3, train4, train5, train6, train7, train8, train9)\n","accuracy = getAccuracy(test_images, test_labels, 'normal', mean_0, mean_1, mean_2, mean_3, mean_4, mean_5, mean_6, mean_7, mean_8, mean_9, \n","                       var_0, var_1, var_2, var_3, var_4, var_5, var_6, var_7, var_8, var_9, \n","                       [P_0, P_1, P_2, P_3, P_4, P_5, P_6, P_7, P_8, P_9], nonzerovarrow)\n","print('Accuracy: ', accuracy)\n","      \n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iBgk7P4Gmgmh","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","\n","def generateShape(d, n):\n","  d.shape=(n, n)\n","  plt.imshow(d,cmap='gray')\n","  plt.show()\n","    \n","generateShape(mean_0, 28)\n","generateShape(mean_1, 28)\n","generateShape(mean_2, 28)\n","generateShape(mean_3, 28)\n","generateShape(mean_4, 28)\n","generateShape(mean_5, 28)\n","generateShape(mean_6, 28)\n","generateShape(mean_7, 28)\n","generateShape(mean_8, 28)\n","generateShape(mean_9, 28)  "],"execution_count":0,"outputs":[]}]}